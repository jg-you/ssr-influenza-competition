
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### get ssr fit -- prediction horizons 1:52
> library(lubridate)
> library(ggplot2)
> library(plyr)

Attaching package: ‘plyr’

The following object is masked from ‘package:lubridate’:

    here

> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:plyr’:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

The following objects are masked from ‘package:lubridate’:

    intersect, setdiff, union

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(reshape)

Attaching package: ‘reshape’

The following object is masked from ‘package:dplyr’:

    rename

The following objects are masked from ‘package:plyr’:

    rename, round_any

The following object is masked from ‘package:lubridate’:

    stamp

> library(ssrFlu)
> library(doMC)
Loading required package: foreach
Loading required package: iterators
Loading required package: parallel
> 
> registerDoMC(cores=3)
> 
> args <- commandArgs(trailingOnly=TRUE)
> 
> data_set <- args[1]
> prediction_horizon_limit <- as.integer(args[2])
> 
> ## load dataset
> if(identical(data_set, "ili_national")) {
+     data <- ili_national
+ } 
> if(identical(data_set, "ili_region1")) {
+     data <- ili_region1
+ } 
> if(identical(data_set, "ili_region2")) {
+     data <- ili_region2
+ } 
> if(identical(data_set, "ili_region3")) {
+     data <- ili_region3
+ } 
> if(identical(data_set, "ili_region4")) {
+     data <- ili_region4
+ } 
> if(identical(data_set, "ili_region5")) {
+     data <- ili_region5
+ } 
> if(identical(data_set, "ili_region6")) {
+     data <- ili_region6
+ } 
> if(identical(data_set, "ili_region7")) {
+     data <- ili_region7
+ } 
> if(identical(data_set, "ili_region8")) {
+     data <- ili_region8
+ } 
> if(identical(data_set, "ili_region9")) {
+     data <- ili_region9
+ } 
> if(identical(data_set, "ili_region10")) {
+     data <- ili_region10
+ } 
> 
> 
> 
> ## add log column
> data$log_total_cases <- log(data$total_cases + 1)
> 
> ## add week_start_date
> char_dates <- paste(data$year, data$week, "1")
> data$week_start_date <- as.Date(char_dates, format="%Y %W %w")
> 
> ## remove week 53s
> data <- data[-which(is.na(data$week_start_date)),]
> data <- data[262:nrow(data),]
> 
> ## add smooth log column -- or not, since it is already pretty smooth...
> sm <- loess(log_total_cases ~ as.numeric(week_start_date), data=data, span= 26 / nrow(data))
> data$smooth_log_cases <- sm$fitted
> 
> ## add time column
> data$time_ind <- seq_len(nrow(data))
> 
> ssr_control <- create_ssr_control(X_names=c("smooth_log_cases", "time_ind"),
+     y_names="total_cases",
+     time_name=NULL,
+     max_lag=list(smooth_log_cases=1,
+         time_ind=0),
+     prediction_horizons=as.integer(prediction_horizon_limit),
+     kernel_fns=list(smooth_log_cases="squared_exp_kernel",
+         time_ind="periodic_kernel"),
+     theta_est=list(smooth_log_cases="bw",
+         time_ind="bw"),
+     theta_fixed=list(time_ind=list(period=pi / 52)),
+     theta_transform_fns=list(
+         squared_exp_kernel=list(
+             bw=list(transform="log",
+                 detransform="exp")
+         ),
+         periodic_kernel=list(
+             bw=list(transform="log",
+                 detransform="exp")
+         )
+     ),
+     crossval_buffer=52,
+     loss_fn_name="mae_from_kernel_weights_and_centers",
+     loss_fn_args=list())
> 
> 
> ssr_fit <- ssr(X_names=c("smooth_log_cases", "time_ind"),
+     y_names="total_cases",
+     time_name=NULL,
+     data=data,
+     ssr_control=ssr_control)
431.3836FALSE
431.3837FALSE
415.0683FALSE
353.5798FALSE
431.3835FALSE
415.0708FALSE
440.78FALSE
353.5702FALSE
440.7761FALSE
415.0658FALSE
440.7838FALSE
353.5895FALSE
431.3835FALSE
427.143FALSE
352.368FALSE
431.3835FALSE
431.3834FALSE
352.3941FALSE
427.1331FALSE
431.3833FALSE
352.342FALSE
431.3833FALSE
427.1528FALSE
351.3103FALSE
431.3833FALSE
414.9874FALSE
351.3025FALSE
431.3833FALSE
414.9886FALSE
351.3182FALSE
431.3833FALSE
414.9862FALSE
388.4427FALSE
431.3833FALSE
$par
smooth_log_cases_lag1.bw 
               -2.309925 

$value
[1] 431.3833

$counts
function gradient 
       5        5 

$convergence
[1] 0

$message
[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"

415.0788FALSE
388.5821FALSE
415.0758FALSE
388.3033FALSE
415.0819FALSE
349.4739FALSE
414.9892FALSE
414.9871FALSE
349.4697FALSE
414.9913FALSE
349.4781FALSE
414.9859FALSE
350.0934FALSE
414.9871FALSE
350.1072FALSE
414.9863FALSE
350.0798FALSE
414.9855FALSE
349.0331FALSE
414.9864FALSE
349.0314FALSE
414.9875FALSE
349.0347FALSE
414.9857FALSE
349.1459FALSE
414.9868FALSE
414.9868FALSE
349.1508FALSE
414.9857FALSE
349.141FALSE
414.9868FALSE
348.9977FALSE
414.9868FALSE
$par
smooth_log_cases_lag0.bw 
               -2.344916 

$value
[1] 414.9857

$counts
function gradient 
       9        9 

$convergence
[1] 0

$message
[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"

348.9973FALSE
348.9982FALSE
348.9973FALSE
348.9975FALSE
348.9971FALSE
348.9966FALSE
348.9968FALSE
348.9964FALSE
349.001FALSE
349.0003FALSE
349.0023FALSE
348.9964FALSE
348.9963FALSE
348.9965FALSE
348.9965FALSE
348.9967FALSE
348.9962FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9964FALSE
348.9962FALSE
348.9965FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
348.9963FALSE
348.9964FALSE
348.9964FALSE
$par
time_ind_lag0.bw 
       -1.576204 

$value
[1] 348.9963

$counts
function gradient 
      55       55 

$convergence
[1] 0

$message
[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"

362.9612FALSE
366.5055FALSE
362.9481FALSE
366.4926FALSE
366.5184FALSE
362.9743FALSE
366.5059FALSE
362.9647FALSE
366.5051FALSE
355.1582FALSE
362.9578FALSE
355.1501FALSE
355.1662FALSE
355.2848FALSE
355.1544FALSE
355.1619FALSE
355.2795FALSE
449.5633FALSE
449.5649FALSE
355.2901FALSE
449.5616FALSE
449.6912FALSE
355.2761FALSE
449.4351FALSE
353.6527FALSE
355.2935FALSE
353.6459FALSE
353.6594FALSE
351.1337FALSE
353.6524FALSE
353.653FALSE
351.132FALSE
350.1013FALSE
350.0996FALSE
351.1355FALSE
350.103FALSE
350.103FALSE
351.1417FALSE
350.0997FALSE
349.5786FALSE
351.1258FALSE
349.5776FALSE
349.5797FALSE
350.2295FALSE
349.5775FALSE
349.5798FALSE
350.2276FALSE
349.2746FALSE
349.2742FALSE
350.2313FALSE
349.275FALSE
349.2727FALSE
350.2286FALSE
349.2765FALSE
349.1103FALSE
350.2303FALSE
349.1101FALSE
349.1105FALSE
349.4022FALSE
349.1104FALSE
349.1102FALSE
349.4015FALSE
349.0734FALSE
349.0733FALSE
349.4029FALSE
349.0736FALSE
349.4005FALSE
349.0758FALSE
349.4038FALSE
349.0712FALSE
349.2257FALSE
349.0108FALSE
349.2253FALSE
349.0108FALSE
349.2261FALSE
349.0109FALSE
349.2238FALSE
349.0104FALSE
349.0113FALSE
349.2276FALSE
349.0073FALSE
349.0073FALSE
349.0818FALSE
349.0073FALSE
349.0816FALSE
349.0071FALSE
349.0819FALSE
349.0077FALSE
349.0009FALSE
349.0819FALSE
349.0009FALSE
349.0816FALSE
349.0009FALSE
349.0478FALSE
349.0009FALSE
349.0477FALSE
349.001FALSE
349.0479FALSE
348.9987FALSE
349.048FALSE
348.9987FALSE
349.0476FALSE
348.9987FALSE
349.0236FALSE
348.9988FALSE
349.0236FALSE
348.9988FALSE
349.0237FALSE
348.9975FALSE
349.0242FALSE
348.9975FALSE
349.0233FALSE
348.9975FALSE
349.0686FALSE
348.9976FALSE
349.0686FALSE
348.9976FALSE
349.0686FALSE
349.0001FALSE
349.0668FALSE
349.0001FALSE
349.0704FALSE
349.0001FALSE
349.0146FALSE
348.9996FALSE
349.0145FALSE
349.0006FALSE
349.0146FALSE
348.9975FALSE
349.0148FALSE
348.9975FALSE
349.0144FALSE
348.9975FALSE
349.016FALSE
348.9974FALSE
349.0159FALSE
348.9976FALSE
349.016FALSE
348.9975FALSE
349.0146FALSE
348.9975FALSE
349.0173FALSE
348.9975FALSE
349.0117FALSE
348.9975FALSE
349.0117FALSE
348.9976FALSE
349.0117FALSE
348.9975FALSE
349.0112FALSE
348.9975FALSE
349.0122FALSE
348.9975FALSE
349.0026FALSE
348.9976FALSE
349.0026FALSE
348.9976FALSE
349.0026FALSE
348.9975FALSE
349.0025FALSE
348.9975FALSE
349.0029FALSE
348.9975FALSE
348.9999FALSE
348.9976FALSE
348.9998FALSE
348.9976FALSE
348.9999FALSE
348.9975FALSE
349.0001FALSE
348.9975FALSE
348.9996FALSE
348.9975FALSE
348.9979FALSE
348.9976FALSE
348.9979FALSE
348.9976FALSE
348.9979FALSE
348.9975FALSE
348.9975FALSE
348.9981FALSE
348.9975FALSE
348.998FALSE
348.9976FALSE
348.9972FALSE
348.9976FALSE
348.9972FALSE
348.9975FALSE
348.9972FALSE
348.9975FALSE
348.9971FALSE
348.9973FALSE
348.9975FALSE
348.9966FALSE
348.9976FALSE
348.9966FALSE
348.9976FALSE
348.9966FALSE
348.9975FALSE
348.9968FALSE
348.9975FALSE
348.9968FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9966FALSE
348.9975FALSE
348.9966FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9974FALSE
348.9976FALSE
348.9974FALSE
348.9975FALSE
348.9974FALSE
348.9975FALSE
348.9969FALSE
348.9975FALSE
348.9978FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9964FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9998FALSE
348.9964FALSE
348.9998FALSE
348.9964FALSE
348.9998FALSE
348.9964FALSE
348.9994FALSE
349.0003FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9975FALSE
348.9965FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
349.0014FALSE
348.9976FALSE
349.0014FALSE
348.9976FALSE
349.0014FALSE
348.9975FALSE
349.0005FALSE
348.9975FALSE
349.0028FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9965FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9964FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9965FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9964FALSE
348.9976FALSE
348.9964FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
348.9965FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9975FALSE
348.9964FALSE
348.9976FALSE
348.9965FALSE
348.9976FALSE
$par
smooth_log_cases_lag1.bw         time_ind_lag0.bw 
                3.452124                -1.576250 

$value
[1] 348.9975

$counts
function gradient 
      54       54 

$convergence
[1] 52

$message
[1] "ERROR: ABNORMAL_TERMINATION_IN_LNSRCH"

348.9965FALSE
348.9964FALSE
348.9964FALSE
348.9964FALSE
348.9965FALSE
348.9965FALSE
348.9964FALSE
348.9964FALSE
348.9964FALSE
348.9965FALSE
348.9965FALSE
348.9964FALSE
348.9964FALSE
348.9964FALSE
348.9965FALSE
348.9965FALSE
348.9964FALSE
348.9964FALSE
348.9964FALSE
348.9965FALSE
348.9965FALSE
$par
smooth_log_cases_lag0.bw         time_ind_lag0.bw 
                4.706540                -1.576144 

$value
[1] 348.9964

$counts
function gradient 
      55       55 

$convergence
[1] 0

$message
[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"

> 
> save(ssr_fit,
+     file=paste0("/home/ngr67a/2015-cdc-flu-competition/fit-competition-ssr-ph", prediction_horizon_limit, "-", data_set, ".Rdata"))
> 
> proc.time()
   user  system elapsed 
975.349   0.514 954.122 
